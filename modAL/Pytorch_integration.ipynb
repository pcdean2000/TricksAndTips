{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch models in modAL workflows\n",
    "=============================\n",
    "\n",
    "Thanks to Skorch API, you can seamlessly integrate Pytorch models into your modAL workflow. In this tutorial, we shall quickly introduce how to use Skorch API of Keras and we are going to see how to do active learning with it. More details on the Keras scikit-learn API [can be found here](https://skorch.readthedocs.io/en/stable/).\n",
    "\n",
    "The executable script for this example can be [found here](https://github.com/cosmic-cortex/modAL/blob/master/examples/pytorch_integration.py)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skorch API\n",
    "-----------------------\n",
    "\n",
    "By default, a Pytorch model's interface differs from what is used for scikit-learn estimators. However, with the use of Skorch wrapper, it is possible to adapt your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "# build class for the skorch API\n",
    "class Torch_Model(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Torch_Model, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "                                nn.Conv2d(1,32,3),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(32,64,3),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(2),\n",
    "                                nn.Dropout(0.25)\n",
    "        )\n",
    "        self.fcs = nn.Sequential(\n",
    "                                nn.Linear(12*12*64,128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(128,10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.convs(out)\n",
    "        out = out.view(-1,12*12*64)\n",
    "        out = self.fcs(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, the ``classifier`` which we will initialize now acts just like any scikit-learn estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the classifier\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "classifier = NeuralNetClassifier(Torch_Model,\n",
    "                                 criterion=nn.CrossEntropyLoss,\n",
    "                                 optimizer=torch.optim.Adam,\n",
    "                                 train_split=None,\n",
    "                                 verbose=1,\n",
    "                                 device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active learning with Pytorch\n",
    "---------------------------------------\n",
    "\n",
    "In this example, we are going to use the famous MNIST dataset, which is available as a built-in for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:13<00:00, 749390.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 148894.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:04<00:00, 402550.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 6796478.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "mnist_data = MNIST('.', download=True, transform=ToTensor())\n",
    "dataloader = DataLoader(mnist_data, shuffle=True, batch_size=60000)\n",
    "X, y = next(iter(dataloader))\n",
    "\n",
    "# read training data\n",
    "X_train, X_test, y_train, y_test = X[:50000], X[50000:], y[:50000], y[50000:]\n",
    "X_train = X_train.reshape(50000, 1, 28, 28)\n",
    "X_test = X_test.reshape(10000, 1, 28, 28)\n",
    "\n",
    "# assemble initial data\n",
    "n_initial = 1000\n",
    "initial_idx = np.random.choice(range(len(X_train)), size=n_initial, replace=False)\n",
    "X_initial = X_train[initial_idx]\n",
    "y_initial = y_train[initial_idx]\n",
    "\n",
    "# generate the pool\n",
    "# remove the initial data from the training dataset\n",
    "X_pool = np.delete(X_train, initial_idx, axis=0)[:5000]\n",
    "y_pool = np.delete(y_train, initial_idx, axis=0)[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active learning with data and classifier ready is as easy as always. Because training is *very* expensive in large neural networks, this time we are going to query the best 200 instances each time we measure the uncertainty of the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.8759\u001b[0m  3.9433\n",
      "      2        \u001b[36m2.3035\u001b[0m  0.0360\n",
      "      3        \u001b[36m2.3013\u001b[0m  0.0359\n",
      "      4        \u001b[36m2.3004\u001b[0m  0.0336\n",
      "      5        \u001b[36m2.2997\u001b[0m  0.0348\n",
      "      6        \u001b[36m2.2993\u001b[0m  0.0355\n",
      "      7        \u001b[36m2.2986\u001b[0m  0.0337\n",
      "      8        2.2992  0.0357\n",
      "      9        2.3001  0.0350\n",
      "     10        2.2994  0.0346\n"
     ]
    }
   ],
   "source": [
    "from modAL.models import ActiveLearner\n",
    "\n",
    "# initialize ActiveLearner\n",
    "learner = ActiveLearner(\n",
    "    estimator=classifier,\n",
    "    X_training=X_initial, y_training=y_initial,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that you train only on newly queried labels, pass ``only_new=True`` to the ``.teach()`` method of the learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query no. 1\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3189\u001b[0m  0.0071\n",
      "      2        4.2473  0.0041\n",
      "      3        2.6374  0.0041\n",
      "      4        \u001b[36m2.2374\u001b[0m  0.0040\n",
      "      5        \u001b[36m2.1513\u001b[0m  0.0048\n",
      "      6        \u001b[36m2.0951\u001b[0m  0.0044\n",
      "      7        \u001b[36m1.9428\u001b[0m  0.0038\n",
      "      8        \u001b[36m1.8126\u001b[0m  0.0039\n",
      "      9        \u001b[36m1.5575\u001b[0m  0.0049\n",
      "     10        \u001b[36m1.3876\u001b[0m  0.0039\n",
      "Query no. 2\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2986\u001b[0m  0.0042\n",
      "      2       27.0114  0.0046\n",
      "      3        4.0127  0.0039\n",
      "      4        \u001b[36m2.2890\u001b[0m  0.0041\n",
      "      5        2.3036  0.0041\n",
      "      6        2.2992  0.0038\n",
      "      7        2.2942  0.0046\n",
      "      8        \u001b[36m2.2889\u001b[0m  0.0041\n",
      "      9        \u001b[36m2.2813\u001b[0m  0.0040\n",
      "     10        \u001b[36m2.2751\u001b[0m  0.0044\n",
      "Query no. 3\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3105\u001b[0m  0.0042\n",
      "      2        5.0803  0.0049\n",
      "      3        2.6852  0.0053\n",
      "      4        \u001b[36m2.2979\u001b[0m  0.0040\n",
      "      5        \u001b[36m2.2960\u001b[0m  0.0057\n",
      "      6        \u001b[36m2.2843\u001b[0m  0.0045\n",
      "      7        \u001b[36m2.2647\u001b[0m  0.0038\n",
      "      8        \u001b[36m2.2223\u001b[0m  0.0043\n",
      "      9        \u001b[36m2.1852\u001b[0m  0.0049\n",
      "     10        \u001b[36m2.1155\u001b[0m  0.0045\n",
      "Query no. 4\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3077\u001b[0m  0.0041\n",
      "      2        8.9569  0.0037\n",
      "      3        2.9375  0.0045\n",
      "      4        \u001b[36m2.2688\u001b[0m  0.0039\n",
      "      5        \u001b[36m2.2532\u001b[0m  0.0040\n",
      "      6        \u001b[36m2.1678\u001b[0m  0.0045\n",
      "      7        \u001b[36m2.0266\u001b[0m  0.0042\n",
      "      8        \u001b[36m1.8922\u001b[0m  0.0038\n",
      "      9        \u001b[36m1.8794\u001b[0m  0.0039\n",
      "     10        \u001b[36m1.6961\u001b[0m  0.0045\n",
      "Query no. 5\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2827\u001b[0m  0.0044\n",
      "      2        9.0219  0.0037\n",
      "      3        2.4260  0.0046\n",
      "      4        \u001b[36m2.1339\u001b[0m  0.0037\n",
      "      5        2.2110  0.0048\n",
      "      6        \u001b[36m2.1193\u001b[0m  0.0046\n",
      "      7        \u001b[36m1.9204\u001b[0m  0.0042\n",
      "      8        \u001b[36m1.6809\u001b[0m  0.0035\n",
      "      9        \u001b[36m1.4964\u001b[0m  0.0038\n",
      "     10        \u001b[36m1.4001\u001b[0m  0.0069\n",
      "Query no. 6\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3278\u001b[0m  0.0041\n",
      "      2        9.8741  0.0044\n",
      "      3        5.1627  0.0047\n",
      "      4        \u001b[36m2.2798\u001b[0m  0.0051\n",
      "      5        \u001b[36m2.1097\u001b[0m  0.0052\n",
      "      6        \u001b[36m1.8840\u001b[0m  0.0053\n",
      "      7        \u001b[36m1.6251\u001b[0m  0.0039\n",
      "      8        \u001b[36m1.4348\u001b[0m  0.0040\n",
      "      9        \u001b[36m1.3594\u001b[0m  0.0044\n",
      "     10        \u001b[36m1.3033\u001b[0m  0.0052\n",
      "Query no. 7\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2887\u001b[0m  0.0037\n",
      "      2        8.7798  0.0038\n",
      "      3        2.8746  0.0039\n",
      "      4        \u001b[36m2.2706\u001b[0m  0.0038\n",
      "      5        \u001b[36m2.2683\u001b[0m  0.0049\n",
      "      6        \u001b[36m2.2611\u001b[0m  0.0039\n",
      "      7        \u001b[36m2.2537\u001b[0m  0.0047\n",
      "      8        \u001b[36m2.2455\u001b[0m  0.0052\n",
      "      9        \u001b[36m2.2381\u001b[0m  0.0038\n",
      "     10        \u001b[36m2.2286\u001b[0m  0.0049\n",
      "Query no. 8\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2950\u001b[0m  0.0040\n",
      "      2        5.6557  0.0042\n",
      "      3        3.2920  0.0039\n",
      "      4        \u001b[36m2.2309\u001b[0m  0.0041\n",
      "      5        \u001b[36m2.2172\u001b[0m  0.0044\n",
      "      6        \u001b[36m2.1628\u001b[0m  0.0038\n",
      "      7        \u001b[36m2.0134\u001b[0m  0.0048\n",
      "      8        \u001b[36m1.8124\u001b[0m  0.0044\n",
      "      9        \u001b[36m1.6265\u001b[0m  0.0037\n",
      "     10        \u001b[36m1.4229\u001b[0m  0.0049\n",
      "Query no. 9\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2821\u001b[0m  0.0037\n",
      "      2        \u001b[36m1.0413\u001b[0m  0.0038\n",
      "      3        \u001b[36m0.4010\u001b[0m  0.0039\n",
      "      4        0.4261  0.0047\n",
      "      5        0.4036  0.0045\n",
      "      6        \u001b[36m0.3153\u001b[0m  0.0045\n",
      "      7        0.4481  0.0039\n",
      "      8        \u001b[36m0.3081\u001b[0m  0.0046\n",
      "      9        \u001b[36m0.1830\u001b[0m  0.0048\n",
      "     10        0.2977  0.0039\n",
      "Query no. 10\n",
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2912\u001b[0m  0.0054\n",
      "      2       18.3569  0.0037\n",
      "      3        3.3802  0.0037\n",
      "      4        \u001b[36m2.2058\u001b[0m  0.0037\n",
      "      5        \u001b[36m2.0798\u001b[0m  0.0042\n",
      "      6        \u001b[36m1.8775\u001b[0m  0.0047\n",
      "      7        \u001b[36m1.6304\u001b[0m  0.0040\n",
      "      8        1.8221  0.0058\n",
      "      9        1.7779  0.0042\n",
      "     10        \u001b[36m1.6073\u001b[0m  0.0038\n"
     ]
    }
   ],
   "source": [
    "# the active learning loop\n",
    "n_queries = 10\n",
    "for idx in range(n_queries):\n",
    "    print('Query no. %d' % (idx + 1))\n",
    "    query_idx, query_instance = learner.query(X_pool, n_instances=100)\n",
    "    learner.teach(\n",
    "        X=X_pool[query_idx], y=y_pool[query_idx], only_new=True,\n",
    "    )\n",
    "    # remove queried instance from pool\n",
    "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "    y_pool = np.delete(y_pool, query_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
